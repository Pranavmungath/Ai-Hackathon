{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "from datetime import datetime\n",
    "from pydantic import BaseModel, Field\n",
    "from openai import OpenAI\n",
    "import requests\n",
    "import logging\n",
    "import json\n",
    "from collections import defaultdict\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"https://api.groq.com/openai/v1\",\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama-3.3-70b-versatile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You're a helpful assistant.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a limerick about the Python programming language.\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-8cff838a-c9b7-4701-a859-bf3795022f47',\n",
       " 'choices': [{'finish_reason': 'stop',\n",
       "   'index': 0,\n",
       "   'logprobs': None,\n",
       "   'message': {'content': 'There once was a Python so fine,\\nWhose code was easy to design.\\nIt ran with great pace,\\nAnd a gentle face,\\nAnd its libraries were truly divine.',\n",
       "    'refusal': None,\n",
       "    'role': 'assistant',\n",
       "    'annotations': None,\n",
       "    'audio': None,\n",
       "    'function_call': None,\n",
       "    'tool_calls': None}}],\n",
       " 'created': 1743039233,\n",
       " 'model': 'llama-3.3-70b-versatile',\n",
       " 'object': 'chat.completion',\n",
       " 'service_tier': None,\n",
       " 'system_fingerprint': 'fp_8dd9fca28c',\n",
       " 'usage': {'completion_tokens': 35,\n",
       "  'prompt_tokens': 52,\n",
       "  'total_tokens': 87,\n",
       "  'completion_tokens_details': None,\n",
       "  'prompt_tokens_details': None,\n",
       "  'queue_time': 0.10126533,\n",
       "  'prompt_time': 0.002585022,\n",
       "  'completion_time': 0.127272727,\n",
       "  'total_time': 0.129857749},\n",
       " 'x_groq': {'id': 'req_01jqakqz9qe3kvbs4j553vd5c9'}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class check_prompt(BaseModel):\n",
    "    \"\"\"First LLM call: Extract basic accomodation information\"\"\"\n",
    "\n",
    "    # description: str = Field(description=\"Raw description of the event\")\n",
    "    is_accomodation_search: bool = Field(\n",
    "        description=\"Is the text a query related to finding an accomodation?\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accomodation_request(input_prompt: str):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": f\"\"\"\n",
    "                    You are an assistant for finding accomodation. \n",
    "                    You are allowed to answer only to queries related to accomodation search.\n",
    "                    In case of other requests, you must decline.\n",
    "                    In this context, Analyze if the text describes a query for finding accomodation.\n",
    "                    Say yes if the text describes a query for finding accomodation, else say no.\n",
    "                    Output should be in json format.\n",
    "                    {json.dumps(check_prompt.model_json_schema(), indent=2)}\n",
    "                    \"\"\" \n",
    "            },\n",
    "            {\"role\": \"user\", \"content\": input_prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "\n",
    "    return check_prompt.model_validate_json(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Suggest me some hotels in Bengaluru for staying from 27th March 2025 and 31st March 2025\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "check_prompt(is_accomodation_search=True)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_accomodation_request(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
